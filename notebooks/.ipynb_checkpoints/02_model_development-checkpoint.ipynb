{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ðŸ“Š Forex Signal Model - Phase 2: Model Development\n",
                "\n",
                "This notebook trains and evaluates three baseline models:\n",
                "1. **Technical Rules System** - Rule-based signals\n",
                "2. **XGBoost Classifier** - ML-based pattern recognition\n",
                "3. **Ensemble** - Combined approach\n",
                "\n",
                "## Setup"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import sys\n",
                "import warnings\n",
                "from pathlib import Path\n",
                "\n",
                "# Add project root to path\n",
                "project_root = Path.cwd().parent\n",
                "sys.path.insert(0, str(project_root))\n",
                "\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "\n",
                "# Set style\n",
                "plt.style.use('seaborn-v0_8-darkgrid')\n",
                "sns.set_palette('husl')\n",
                "%matplotlib inline\n",
                "\n",
                "print(f\"Project root: {project_root}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Load Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load features\n",
                "features_path = project_root / 'data' / 'processed' / 'features.parquet'\n",
                "df = pd.read_parquet(features_path)\n",
                "\n",
                "print(f\"Data shape: {df.shape}\")\n",
                "print(f\"Date range: {df.index.min()} to {df.index.max()}\")\n",
                "print(f\"Columns: {len(df.columns)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Check target balance\n",
                "target_cols = [c for c in df.columns if 'Target_Direction' in c]\n",
                "print(\"\\nTarget Distribution:\")\n",
                "for col in target_cols:\n",
                "    counts = df[col].value_counts(normalize=True)\n",
                "    print(f\"  {col}: {counts.to_dict()}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Train/Test split (time-based)\n",
                "split_idx = int(len(df) * 0.8)\n",
                "train_df = df.iloc[:split_idx]\n",
                "test_df = df.iloc[split_idx:]\n",
                "\n",
                "print(f\"Train: {len(train_df)} samples ({train_df.index.min()} to {train_df.index.max()})\")\n",
                "print(f\"Test: {len(test_df)} samples ({test_df.index.min()} to {test_df.index.max()})\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Technical Rules System"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from src.models.technical_rules import TechnicalRulesSystem\n",
                "\n",
                "# Initialize\n",
                "tech_system = TechnicalRulesSystem(str(project_root / 'config' / 'config.yaml'))\n",
                "\n",
                "# Generate signals\n",
                "tech_signals = tech_system.generate_all_signals(df)\n",
                "tech_summary = tech_system.get_signal_summary(tech_signals)\n",
                "\n",
                "print(\"\\nTechnical Rules Summary:\")\n",
                "for k, v in tech_summary.items():\n",
                "    print(f\"  {k}: {v}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Signal distribution by ticker\n",
                "fig, ax = plt.subplots(figsize=(10, 5))\n",
                "tech_signals.groupby(['Ticker', 'Signal']).size().unstack(fill_value=0).plot(\n",
                "    kind='bar', ax=ax, color=['red', 'gray', 'green'])\n",
                "ax.set_title('Technical Rules Signal Distribution')\n",
                "ax.set_xlabel('Ticker')\n",
                "ax.set_ylabel('Count')\n",
                "ax.legend(['SELL', 'HOLD', 'BUY'])\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Confidence distribution\n",
                "fig, ax = plt.subplots(figsize=(10, 5))\n",
                "tech_signals['Confidence'].hist(bins=20, ax=ax, color='steelblue', alpha=0.7)\n",
                "ax.axvline(x=40, color='red', linestyle='--', label='Min threshold')\n",
                "ax.set_title('Technical Rules Confidence Distribution')\n",
                "ax.set_xlabel('Confidence')\n",
                "ax.set_ylabel('Frequency')\n",
                "ax.legend()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. XGBoost Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from src.models.ml_models import XGBoostTradingModel\n",
                "\n",
                "# Initialize and train\n",
                "xgb_model = XGBoostTradingModel(str(project_root / 'config' / 'config.yaml'))\n",
                "\n",
                "# Train for all tickers (no hyperparameter tuning for speed)\n",
                "xgb_metrics = xgb_model.train_all(df, tune_hyperparams=False)\n",
                "\n",
                "print(\"\\nXGBoost Training Results:\")\n",
                "for ticker, m in xgb_metrics.items():\n",
                "    if 'error' not in m:\n",
                "        print(f\"  {ticker}: Val Acc={m['val_accuracy']:.3f}, Test Acc={m['test_accuracy']:.3f}, AUC={m.get('test_auc', 0):.3f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Feature importance for each ticker\n",
                "fig, axes = plt.subplots(1, len(xgb_model.feature_importance), figsize=(15, 6))\n",
                "if len(xgb_model.feature_importance) == 1:\n",
                "    axes = [axes]\n",
                "\n",
                "for ax, (ticker, importance) in zip(axes, xgb_model.feature_importance.items()):\n",
                "    top10 = importance.head(10)\n",
                "    ax.barh(range(len(top10)), top10['importance'].values, color='steelblue')\n",
                "    ax.set_yticks(range(len(top10)))\n",
                "    ax.set_yticklabels(top10['feature'].values)\n",
                "    ax.invert_yaxis()\n",
                "    ax.set_title(f'{ticker} Top 10 Features')\n",
                "    ax.set_xlabel('Importance')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Generate predictions\n",
                "xgb_signals = xgb_model.predict_all(df)\n",
                "print(f\"\\nXGBoost signals: {len(xgb_signals)} total\")\n",
                "print(xgb_signals.groupby(['Ticker', 'Signal']).size().unstack(fill_value=0))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Ensemble Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from src.models.ensemble import EnsembleModel\n",
                "\n",
                "# Initialize and train\n",
                "ensemble = EnsembleModel(str(project_root / 'config' / 'config.yaml'))\n",
                "ensemble_results = ensemble.train(df, tune_hyperparams=False)\n",
                "\n",
                "# Generate predictions\n",
                "ensemble_signals = ensemble.predict(df)\n",
                "ensemble_analysis = ensemble.get_signal_analysis(ensemble_signals)\n",
                "\n",
                "print(\"\\nEnsemble Analysis:\")\n",
                "for k, v in ensemble_analysis.items():\n",
                "    print(f\"  {k}: {v}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Model agreement\n",
                "agreement_rate = ensemble_signals['Agreement'].mean() * 100\n",
                "print(f\"\\nTechnical + XGBoost Agreement Rate: {agreement_rate:.1f}%\")\n",
                "\n",
                "# Compare signals when models agree vs disagree\n",
                "agree = ensemble_signals[ensemble_signals['Agreement'] == 1]\n",
                "disagree = ensemble_signals[ensemble_signals['Agreement'] == 0]\n",
                "\n",
                "print(f\"Signals when agreeing: {len(agree)}\")\n",
                "print(f\"Signals when disagreeing: {len(disagree)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Backtesting"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from src.backtesting.engine import BacktestEngine\n",
                "from src.backtesting.metrics import calculate_performance_metrics, format_metrics_report\n",
                "\n",
                "# Initialize backtest engine\n",
                "engine = BacktestEngine(str(project_root / 'config' / 'config.yaml'))\n",
                "\n",
                "# Filter to test period only\n",
                "test_start = test_df.index.min()\n",
                "print(f\"Backtesting on test period: {test_start} onwards\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Backtest Technical Rules\n",
                "tech_test = tech_signals.copy()\n",
                "tech_test['Date'] = pd.to_datetime(tech_test['Date'])\n",
                "tech_test = tech_test[tech_test['Date'] >= test_start]\n",
                "\n",
                "engine.reset()\n",
                "tech_results = engine.run_backtest(tech_test, test_df)\n",
                "\n",
                "if not tech_results['trades_df'].empty:\n",
                "    tech_metrics = calculate_performance_metrics(tech_results['trades_df'], tech_results['equity_df'])\n",
                "    print(\"\\n\" + format_metrics_report(tech_metrics))\n",
                "else:\n",
                "    tech_metrics = {}\n",
                "    print(\"No trades executed for Technical Rules\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Backtest XGBoost\n",
                "xgb_test = xgb_signals.copy()\n",
                "xgb_test['Date'] = pd.to_datetime(xgb_test['Date'])\n",
                "xgb_test = xgb_test[xgb_test['Date'] >= test_start]\n",
                "\n",
                "engine.reset()\n",
                "xgb_results = engine.run_backtest(xgb_test, test_df)\n",
                "\n",
                "if not xgb_results['trades_df'].empty:\n",
                "    xgb_metrics = calculate_performance_metrics(xgb_results['trades_df'], xgb_results['equity_df'])\n",
                "    print(\"\\n\" + format_metrics_report(xgb_metrics))\n",
                "else:\n",
                "    xgb_metrics = {}\n",
                "    print(\"No trades executed for XGBoost\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Backtest Ensemble\n",
                "ens_test = ensemble_signals.copy()\n",
                "ens_test['Date'] = pd.to_datetime(ens_test['Date'])\n",
                "ens_test = ens_test[ens_test['Date'] >= test_start]\n",
                "\n",
                "engine.reset()\n",
                "ens_results = engine.run_backtest(ens_test, test_df)\n",
                "\n",
                "if not ens_results['trades_df'].empty:\n",
                "    ens_metrics = calculate_performance_metrics(ens_results['trades_df'], ens_results['equity_df'])\n",
                "    print(\"\\n\" + format_metrics_report(ens_metrics))\n",
                "else:\n",
                "    ens_metrics = {}\n",
                "    print(\"No trades executed for Ensemble\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Model Comparison"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create comparison table\n",
                "comparison_data = []\n",
                "\n",
                "for name, metrics in [('Technical Rules', tech_metrics), ('XGBoost', xgb_metrics), ('Ensemble', ens_metrics)]:\n",
                "    if metrics:\n",
                "        comparison_data.append({\n",
                "            'Model': name,\n",
                "            'Return (%)': metrics.get('total_return_pct', 0),\n",
                "            'Sharpe': metrics.get('sharpe_ratio', 0),\n",
                "            'Win Rate (%)': metrics.get('win_rate', 0),\n",
                "            'Profit Factor': metrics.get('profit_factor', 0),\n",
                "            'Max DD (%)': metrics.get('max_drawdown_pct', 0),\n",
                "            'Total Trades': metrics.get('total_trades', 0)\n",
                "        })\n",
                "\n",
                "comparison_df = pd.DataFrame(comparison_data)\n",
                "print(\"\\n\" + \"=\" * 80)\n",
                "print(\"MODEL COMPARISON\")\n",
                "print(\"=\" * 80)\n",
                "print(comparison_df.to_string(index=False))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Plot equity curves\n",
                "from src.backtesting.visualizations import plot_equity_curve\n",
                "\n",
                "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
                "\n",
                "results_list = [\n",
                "    ('Technical Rules', tech_results),\n",
                "    ('XGBoost', xgb_results),\n",
                "    ('Ensemble', ens_results)\n",
                "]\n",
                "\n",
                "for ax, (name, results) in zip(axes, results_list):\n",
                "    if not results['equity_df'].empty:\n",
                "        equity = results['equity_df']\n",
                "        ax.plot(equity['date'], equity['equity'], linewidth=2)\n",
                "        ax.axhline(y=10000, color='gray', linestyle='--', alpha=0.5)\n",
                "        ax.set_title(f'{name}')\n",
                "        ax.set_xlabel('Date')\n",
                "        ax.set_ylabel('Equity ($)')\n",
                "        ax.tick_params(axis='x', rotation=45)\n",
                "    else:\n",
                "        ax.text(0.5, 0.5, 'No data', ha='center', va='center', transform=ax.transAxes)\n",
                "        ax.set_title(f'{name}')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Save Models"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save models\n",
                "models_dir = project_root / 'models'\n",
                "models_dir.mkdir(exist_ok=True)\n",
                "\n",
                "# Save XGBoost models\n",
                "for ticker in xgb_model.models.keys():\n",
                "    xgb_model.save_model(ticker)\n",
                "\n",
                "# Save ensemble\n",
                "ensemble.save(str(models_dir / 'ensemble'))\n",
                "\n",
                "print(\"Models saved to models/ directory\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save comparison results\n",
                "results_dir = project_root / 'results'\n",
                "results_dir.mkdir(exist_ok=True)\n",
                "\n",
                "comparison_df.to_csv(results_dir / 'model_comparison.csv', index=False)\n",
                "print(f\"Comparison saved to {results_dir / 'model_comparison.csv'}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Summary\n",
                "\n",
                "Phase 2 complete! We trained and evaluated:\n",
                "- Technical Rules: Rule-based system with 7 conditions\n",
                "- XGBoost: ML classifier with feature selection\n",
                "- Ensemble: Weighted combination (40% rules, 60% ML)\n",
                "\n",
                "**Next Steps (Phase 3):**\n",
                "- Walk-forward validation\n",
                "- Hyperparameter optimization\n",
                "- Production deployment"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.11.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}