{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forex Signal Model - Data Exploration\n",
    "\n",
    "This notebook provides comprehensive EDA for the forex signal model:\n",
    "1. Data Quality Check\n",
    "2. Price Visualization\n",
    "3. Intermarket Analysis\n",
    "4. Technical Indicators\n",
    "5. Feature Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Add parent directory to path\n",
    "sys.path.insert(0, str(Path.cwd().parent))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Project imports\n",
    "from src.utils import load_config\n",
    "\n",
    "# Settings\n",
    "pd.set_option('display.max_columns', 50)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "# Load config\n",
    "config = load_config('../config/config.yaml')\n",
    "print(\"Config loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Data Quality Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load combined data\n",
    "combined_path = Path('../' + config['data']['paths']['combined'])\n",
    "features_path = Path('../' + config['data']['paths']['features'])\n",
    "\n",
    "if combined_path.exists():\n",
    "    combined_data = pd.read_parquet(combined_path)\n",
    "    print(f\"Combined data shape: {combined_data.shape}\")\n",
    "    print(f\"Date range: {combined_data.index.min()} to {combined_data.index.max()}\")\n",
    "    print(f\"Total trading days: {len(combined_data)}\")\n",
    "else:\n",
    "    print(f\"Combined data not found at {combined_path}\")\n",
    "    print(\"Run: python main.py --mode download\")\n",
    "    combined_data = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data overview\n",
    "if combined_data is not None:\n",
    "    print(\"=\" * 60)\n",
    "    print(\"DATA OVERVIEW\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"\\nColumns ({len(combined_data.columns)}):\")\n",
    "    for i, col in enumerate(combined_data.columns, 1):\n",
    "        print(f\"  {i:2d}. {col}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"SUMMARY STATISTICS\")\n",
    "    print(\"=\" * 60)\n",
    "    display(combined_data.describe().round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing values analysis\n",
    "if combined_data is not None:\n",
    "    missing = combined_data.isna().sum()\n",
    "    missing_pct = (missing / len(combined_data) * 100).round(2)\n",
    "    \n",
    "    missing_df = pd.DataFrame({\n",
    "        'Missing Count': missing,\n",
    "        'Missing %': missing_pct\n",
    "    })\n",
    "    \n",
    "    print(\"MISSING VALUES\")\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"Total missing cells: {missing.sum()}\")\n",
    "    print(f\"Total cells: {combined_data.size}\")\n",
    "    print(f\"Missing %: {missing.sum() / combined_data.size * 100:.4f}%\")\n",
    "    \n",
    "    if missing.sum() > 0:\n",
    "        print(\"\\nColumns with missing values:\")\n",
    "        display(missing_df[missing_df['Missing Count'] > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data completeness heatmap\n",
    "if combined_data is not None:\n",
    "    # Sample for visualization (too many rows would be slow)\n",
    "    sample_size = min(500, len(combined_data))\n",
    "    sample_idx = np.linspace(0, len(combined_data)-1, sample_size, dtype=int)\n",
    "    sample_data = combined_data.iloc[sample_idx]\n",
    "    \n",
    "    plt.figure(figsize=(14, 8))\n",
    "    sns.heatmap(\n",
    "        sample_data.isna().T,\n",
    "        cbar=True,\n",
    "        cmap='YlOrRd',\n",
    "        yticklabels=True\n",
    "    )\n",
    "    plt.title('Data Completeness Heatmap (Yellow = Missing)', fontsize=14)\n",
    "    plt.xlabel('Time Index')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Price Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract main pair close prices\n",
    "if combined_data is not None:\n",
    "    main_tickers = ['GBPUSD', 'EURUSD', 'XAUUSD']\n",
    "    close_cols = [f'{t}_Close' for t in main_tickers if f'{t}_Close' in combined_data.columns]\n",
    "    \n",
    "    if close_cols:\n",
    "        prices = combined_data[close_cols].copy()\n",
    "        prices.columns = [c.replace('_Close', '') for c in prices.columns]\n",
    "        \n",
    "        # Normalize to 100 for comparison\n",
    "        normalized = prices / prices.iloc[0] * 100\n",
    "        \n",
    "        # Plot normalized prices\n",
    "        fig = px.line(\n",
    "            normalized.reset_index(),\n",
    "            x='Date',\n",
    "            y=normalized.columns.tolist(),\n",
    "            title='Normalized Price Performance (Base = 100)',\n",
    "            labels={'value': 'Normalized Price', 'variable': 'Pair'}\n",
    "        )\n",
    "        fig.update_layout(height=500, hovermode='x unified')\n",
    "        fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Individual candlestick charts\n",
    "def plot_candlestick(df, ticker, last_n_days=252):\n",
    "    \"\"\"Plot candlestick chart for a ticker.\"\"\"\n",
    "    ohlc_cols = [f'{ticker}_{x}' for x in ['Open', 'High', 'Low', 'Close']]\n",
    "    if not all(c in df.columns for c in ohlc_cols):\n",
    "        print(f\"Missing columns for {ticker}\")\n",
    "        return\n",
    "    \n",
    "    # Get last N days\n",
    "    data = df[ohlc_cols].tail(last_n_days).copy()\n",
    "    data.columns = ['Open', 'High', 'Low', 'Close']\n",
    "    \n",
    "    fig = go.Figure(data=[go.Candlestick(\n",
    "        x=data.index,\n",
    "        open=data['Open'],\n",
    "        high=data['High'],\n",
    "        low=data['Low'],\n",
    "        close=data['Close'],\n",
    "        name=ticker\n",
    "    )])\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=f'{ticker} - Last {last_n_days} Trading Days',\n",
    "        yaxis_title='Price',\n",
    "        xaxis_title='Date',\n",
    "        height=400,\n",
    "        xaxis_rangeslider_visible=False\n",
    "    )\n",
    "    fig.show()\n",
    "\n",
    "if combined_data is not None:\n",
    "    for ticker in ['GBPUSD', 'EURUSD', 'XAUUSD']:\n",
    "        plot_candlestick(combined_data, ticker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns distribution\n",
    "if combined_data is not None:\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "    \n",
    "    for i, ticker in enumerate(['GBPUSD', 'EURUSD', 'XAUUSD']):\n",
    "        close_col = f'{ticker}_Close'\n",
    "        if close_col in combined_data.columns:\n",
    "            returns = combined_data[close_col].pct_change() * 100\n",
    "            returns = returns.dropna()\n",
    "            \n",
    "            axes[i].hist(returns, bins=100, edgecolor='black', alpha=0.7)\n",
    "            axes[i].axvline(x=0, color='red', linestyle='--', linewidth=2)\n",
    "            axes[i].axvline(x=returns.mean(), color='green', linestyle='-', linewidth=2, label=f'Mean: {returns.mean():.4f}%')\n",
    "            axes[i].set_title(f'{ticker} Daily Returns')\n",
    "            axes[i].set_xlabel('Return (%)')\n",
    "            axes[i].set_ylabel('Frequency')\n",
    "            axes[i].legend()\n",
    "            \n",
    "            # Print stats\n",
    "            print(f\"{ticker} Returns: Mean={returns.mean():.4f}%, Std={returns.std():.4f}%, Skew={returns.skew():.2f}, Kurt={returns.kurtosis():.2f}\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rolling volatility over time\n",
    "if combined_data is not None:\n",
    "    fig, axes = plt.subplots(3, 1, figsize=(14, 10), sharex=True)\n",
    "    \n",
    "    for i, ticker in enumerate(['GBPUSD', 'EURUSD', 'XAUUSD']):\n",
    "        close_col = f'{ticker}_Close'\n",
    "        if close_col in combined_data.columns:\n",
    "            returns = combined_data[close_col].pct_change() * 100\n",
    "            vol_20 = returns.rolling(20).std()\n",
    "            vol_60 = returns.rolling(60).std()\n",
    "            \n",
    "            axes[i].plot(vol_20.index, vol_20, label='20-day Vol', alpha=0.8)\n",
    "            axes[i].plot(vol_60.index, vol_60, label='60-day Vol', alpha=0.8)\n",
    "            axes[i].set_title(f'{ticker} Rolling Volatility')\n",
    "            axes[i].set_ylabel('Volatility (%)')\n",
    "            axes[i].legend()\n",
    "            axes[i].grid(True, alpha=0.3)\n",
    "    \n",
    "    axes[-1].set_xlabel('Date')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Intermarket Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot intermarket indicators\n",
    "if combined_data is not None:\n",
    "    intermarket_cols = {\n",
    "        'DX_Y_NYB_Close': 'US Dollar Index (DXY)',\n",
    "        'VIX_Close': 'VIX (Volatility Index)',\n",
    "        'TNX_Close': '10Y Treasury Yield',\n",
    "        'CL_F_Close': 'WTI Crude Oil'\n",
    "    }\n",
    "    \n",
    "    available = {k: v for k, v in intermarket_cols.items() if k in combined_data.columns}\n",
    "    \n",
    "    if available:\n",
    "        fig, axes = plt.subplots(len(available), 1, figsize=(14, 3*len(available)), sharex=True)\n",
    "        if len(available) == 1:\n",
    "            axes = [axes]\n",
    "        \n",
    "        for i, (col, name) in enumerate(available.items()):\n",
    "            axes[i].plot(combined_data.index, combined_data[col], linewidth=1)\n",
    "            axes[i].set_title(name)\n",
    "            axes[i].grid(True, alpha=0.3)\n",
    "        \n",
    "        axes[-1].set_xlabel('Date')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"No intermarket data available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation heatmap (all assets)\n",
    "if combined_data is not None:\n",
    "    # Get close price columns only\n",
    "    close_cols = [c for c in combined_data.columns if '_Close' in c]\n",
    "    \n",
    "    if close_cols:\n",
    "        # Calculate returns for correlation\n",
    "        returns = combined_data[close_cols].pct_change().dropna()\n",
    "        \n",
    "        # Correlation matrix\n",
    "        corr = returns.corr()\n",
    "        \n",
    "        # Clean column names for display\n",
    "        corr.columns = [c.replace('_Close', '') for c in corr.columns]\n",
    "        corr.index = [c.replace('_Close', '') for c in corr.index]\n",
    "        \n",
    "        plt.figure(figsize=(10, 8))\n",
    "        mask = np.triu(np.ones_like(corr, dtype=bool), k=1)\n",
    "        sns.heatmap(\n",
    "            corr,\n",
    "            mask=mask,\n",
    "            annot=True,\n",
    "            fmt='.2f',\n",
    "            cmap='RdBu_r',\n",
    "            center=0,\n",
    "            square=True,\n",
    "            linewidths=0.5\n",
    "        )\n",
    "        plt.title('Asset Return Correlations', fontsize=14)\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rolling correlation: FX pairs vs DXY\n",
    "if combined_data is not None and 'DX_Y_NYB_Close' in combined_data.columns:\n",
    "    dxy_returns = combined_data['DX_Y_NYB_Close'].pct_change()\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(14, 5))\n",
    "    \n",
    "    for ticker in ['GBPUSD', 'EURUSD', 'XAUUSD']:\n",
    "        close_col = f'{ticker}_Close'\n",
    "        if close_col in combined_data.columns:\n",
    "            pair_returns = combined_data[close_col].pct_change()\n",
    "            rolling_corr = pair_returns.rolling(60).corr(dxy_returns)\n",
    "            ax.plot(rolling_corr.index, rolling_corr, label=ticker, linewidth=1)\n",
    "    \n",
    "    ax.axhline(y=0, color='black', linestyle='--', linewidth=1)\n",
    "    ax.set_title('60-Day Rolling Correlation vs DXY', fontsize=14)\n",
    "    ax.set_ylabel('Correlation')\n",
    "    ax.set_xlabel('Date')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VIX regime analysis\n",
    "if combined_data is not None and 'VIX_Close' in combined_data.columns:\n",
    "    vix = combined_data['VIX_Close']\n",
    "    \n",
    "    # Define regimes\n",
    "    regime = pd.cut(\n",
    "        vix,\n",
    "        bins=[0, 15, 25, 100],\n",
    "        labels=['Low (<15)', 'Medium (15-25)', 'High (>25)']\n",
    "    )\n",
    "    \n",
    "    # Count days in each regime\n",
    "    regime_counts = regime.value_counts()\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 4))\n",
    "    \n",
    "    # VIX time series\n",
    "    axes[0].plot(vix.index, vix)\n",
    "    axes[0].axhline(y=15, color='green', linestyle='--', label='Low threshold')\n",
    "    axes[0].axhline(y=25, color='red', linestyle='--', label='High threshold')\n",
    "    axes[0].set_title('VIX Over Time')\n",
    "    axes[0].set_ylabel('VIX')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Regime distribution\n",
    "    colors = ['green', 'orange', 'red']\n",
    "    axes[1].pie(\n",
    "        regime_counts,\n",
    "        labels=regime_counts.index,\n",
    "        autopct='%1.1f%%',\n",
    "        colors=colors,\n",
    "        explode=[0.02, 0.02, 0.02]\n",
    "    )\n",
    "    axes[1].set_title('VIX Regime Distribution')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nVIX Regime Statistics:\")\n",
    "    print(regime_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Technical Indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load features if available\n",
    "if features_path.exists():\n",
    "    features = pd.read_parquet(features_path)\n",
    "    print(f\"Features shape: {features.shape}\")\n",
    "    print(f\"Date range: {features.index.min()} to {features.index.max()}\")\n",
    "else:\n",
    "    print(f\"Features not found at {features_path}\")\n",
    "    print(\"Run: python main.py --mode features\")\n",
    "    features = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot GBPUSD with indicators\n",
    "if features is not None:\n",
    "    ticker = 'GBPUSD'\n",
    "    last_n = 252  # 1 year\n",
    "    \n",
    "    data = features.tail(last_n)\n",
    "    \n",
    "    fig = make_subplots(\n",
    "        rows=4, cols=1,\n",
    "        shared_xaxes=True,\n",
    "        vertical_spacing=0.03,\n",
    "        row_heights=[0.4, 0.2, 0.2, 0.2],\n",
    "        subplot_titles=['Price with Bollinger Bands', 'RSI', 'MACD', 'ATR']\n",
    "    )\n",
    "    \n",
    "    # Price and Bollinger Bands\n",
    "    if f'{ticker}_Close' in data.columns:\n",
    "        fig.add_trace(go.Scatter(x=data.index, y=data[f'{ticker}_Close'], name='Close', line=dict(color='blue')), row=1, col=1)\n",
    "    if f'{ticker}_BB_Upper' in data.columns:\n",
    "        fig.add_trace(go.Scatter(x=data.index, y=data[f'{ticker}_BB_Upper'], name='BB Upper', line=dict(color='gray', dash='dash')), row=1, col=1)\n",
    "    if f'{ticker}_BB_Lower' in data.columns:\n",
    "        fig.add_trace(go.Scatter(x=data.index, y=data[f'{ticker}_BB_Lower'], name='BB Lower', line=dict(color='gray', dash='dash')), row=1, col=1)\n",
    "    if f'{ticker}_SMA_20' in data.columns:\n",
    "        fig.add_trace(go.Scatter(x=data.index, y=data[f'{ticker}_SMA_20'], name='SMA20', line=dict(color='orange')), row=1, col=1)\n",
    "    \n",
    "    # RSI\n",
    "    if f'{ticker}_RSI' in data.columns:\n",
    "        fig.add_trace(go.Scatter(x=data.index, y=data[f'{ticker}_RSI'], name='RSI', line=dict(color='purple')), row=2, col=1)\n",
    "        fig.add_hline(y=70, line_dash='dash', line_color='red', row=2, col=1)\n",
    "        fig.add_hline(y=30, line_dash='dash', line_color='green', row=2, col=1)\n",
    "    \n",
    "    # MACD\n",
    "    if f'{ticker}_MACD' in data.columns:\n",
    "        fig.add_trace(go.Scatter(x=data.index, y=data[f'{ticker}_MACD'], name='MACD', line=dict(color='blue')), row=3, col=1)\n",
    "    if f'{ticker}_MACD_Signal' in data.columns:\n",
    "        fig.add_trace(go.Scatter(x=data.index, y=data[f'{ticker}_MACD_Signal'], name='Signal', line=dict(color='orange')), row=3, col=1)\n",
    "    if f'{ticker}_MACD_Histogram' in data.columns:\n",
    "        colors = ['green' if x > 0 else 'red' for x in data[f'{ticker}_MACD_Histogram']]\n",
    "        fig.add_trace(go.Bar(x=data.index, y=data[f'{ticker}_MACD_Histogram'], name='Histogram', marker_color=colors), row=3, col=1)\n",
    "    \n",
    "    # ATR\n",
    "    if f'{ticker}_ATR' in data.columns:\n",
    "        fig.add_trace(go.Scatter(x=data.index, y=data[f'{ticker}_ATR'], name='ATR', line=dict(color='brown')), row=4, col=1)\n",
    "    \n",
    "    fig.update_layout(height=900, title=f'{ticker} - Technical Analysis', showlegend=True)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RSI signal analysis: What happens after RSI < 30?\n",
    "if features is not None:\n",
    "    for ticker in ['GBPUSD', 'EURUSD', 'XAUUSD']:\n",
    "        rsi_col = f'{ticker}_RSI'\n",
    "        target_col = f'{ticker}_Target_Return'\n",
    "        \n",
    "        if rsi_col in features.columns and target_col in features.columns:\n",
    "            df = features[[rsi_col, target_col]].dropna()\n",
    "            \n",
    "            # Oversold (RSI < 30)\n",
    "            oversold = df[df[rsi_col] < 30][target_col]\n",
    "            # Overbought (RSI > 70)\n",
    "            overbought = df[df[rsi_col] > 70][target_col]\n",
    "            # Normal\n",
    "            normal = df[(df[rsi_col] >= 30) & (df[rsi_col] <= 70)][target_col]\n",
    "            \n",
    "            print(f\"\\n{ticker} Next-Day Return by RSI Zone:\")\n",
    "            print(f\"  Oversold (<30): Mean={oversold.mean():.4f}%, Count={len(oversold)}\")\n",
    "            print(f\"  Normal (30-70): Mean={normal.mean():.4f}%, Count={len(normal)}\")\n",
    "            print(f\"  Overbought (>70): Mean={overbought.mean():.4f}%, Count={len(overbought)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Feature Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature correlation heatmap (subset)\n",
    "if features is not None:\n",
    "    # Get feature columns for one ticker\n",
    "    ticker = 'GBPUSD'\n",
    "    ticker_cols = [c for c in features.columns if c.startswith(ticker) and 'Target' not in c]\n",
    "    \n",
    "    if len(ticker_cols) > 0:\n",
    "        # Limit to first 20 features for readability\n",
    "        cols_subset = ticker_cols[:20]\n",
    "        \n",
    "        corr = features[cols_subset].corr()\n",
    "        corr.columns = [c.replace(f'{ticker}_', '') for c in corr.columns]\n",
    "        corr.index = [c.replace(f'{ticker}_', '') for c in corr.index]\n",
    "        \n",
    "        plt.figure(figsize=(14, 12))\n",
    "        sns.heatmap(\n",
    "            corr,\n",
    "            annot=True,\n",
    "            fmt='.2f',\n",
    "            cmap='RdBu_r',\n",
    "            center=0,\n",
    "            square=True,\n",
    "            linewidths=0.5,\n",
    "            annot_kws={'size': 8}\n",
    "        )\n",
    "        plt.title(f'{ticker} Feature Correlations (subset)', fontsize=14)\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance preview using mutual information\n",
    "if features is not None:\n",
    "    from sklearn.feature_selection import mutual_info_classif\n",
    "    \n",
    "    ticker = 'GBPUSD'\n",
    "    target_col = f'{ticker}_Target_Direction'\n",
    "    \n",
    "    if target_col in features.columns:\n",
    "        # Get feature columns\n",
    "        feature_cols = [c for c in features.columns if c.startswith(ticker) and 'Target' not in c]\n",
    "        \n",
    "        # Prepare data\n",
    "        X = features[feature_cols].dropna()\n",
    "        y = features.loc[X.index, target_col]\n",
    "        \n",
    "        # Remove any remaining NaN\n",
    "        mask = ~(X.isna().any(axis=1) | y.isna())\n",
    "        X = X[mask]\n",
    "        y = y[mask]\n",
    "        \n",
    "        if len(X) > 100:\n",
    "            # Calculate mutual information\n",
    "            mi_scores = mutual_info_classif(X, y, random_state=42)\n",
    "            mi_df = pd.DataFrame({\n",
    "                'Feature': [c.replace(f'{ticker}_', '') for c in feature_cols],\n",
    "                'MI Score': mi_scores\n",
    "            }).sort_values('MI Score', ascending=True)\n",
    "            \n",
    "            # Plot top 20\n",
    "            plt.figure(figsize=(10, 8))\n",
    "            plt.barh(mi_df['Feature'].tail(20), mi_df['MI Score'].tail(20))\n",
    "            plt.xlabel('Mutual Information Score')\n",
    "            plt.title(f'{ticker} Top 20 Features by Mutual Information')\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        else:\n",
    "            print(f\"Not enough samples: {len(X)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target distribution (class balance)\n",
    "if features is not None:\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
    "    \n",
    "    for i, ticker in enumerate(['GBPUSD', 'EURUSD', 'XAUUSD']):\n",
    "        target_col = f'{ticker}_Target_Direction'\n",
    "        \n",
    "        if target_col in features.columns:\n",
    "            counts = features[target_col].value_counts()\n",
    "            \n",
    "            axes[i].pie(\n",
    "                counts,\n",
    "                labels=['Down (0)', 'Up (1)'],\n",
    "                autopct='%1.1f%%',\n",
    "                colors=['red', 'green'],\n",
    "                explode=[0.02, 0.02]\n",
    "            )\n",
    "            axes[i].set_title(f'{ticker} Target Distribution')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print exact numbers\n",
    "    print(\"\\nTarget Distribution:\")\n",
    "    for ticker in ['GBPUSD', 'EURUSD', 'XAUUSD']:\n",
    "        target_col = f'{ticker}_Target_Direction'\n",
    "        if target_col in features.columns:\n",
    "            counts = features[target_col].value_counts()\n",
    "            total = len(features[target_col].dropna())\n",
    "            print(f\"  {ticker}: Up={counts.get(1, 0)} ({counts.get(1, 0)/total*100:.1f}%), Down={counts.get(0, 0)} ({counts.get(0, 0)/total*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "This notebook has explored:\n",
    "1. **Data Quality**: Checked for missing values and data completeness\n",
    "2. **Price Visualization**: Normalized prices, candlesticks, returns distribution, volatility\n",
    "3. **Intermarket Analysis**: DXY, VIX, correlations between assets\n",
    "4. **Technical Indicators**: Visual analysis of indicators and their predictive power\n",
    "5. **Feature Analysis**: Correlations, mutual information, target balance\n",
    "\n",
    "### Key Findings\n",
    "- Check the correlation heatmap for multicollinearity\n",
    "- Review VIX regime impacts on returns\n",
    "- Examine RSI signal effectiveness\n",
    "- Note target class balance for model training"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
